{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Input, Dropout, Flatten, Dense\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras import backend as K\n",
    "from keras.applications import VGG16, imagenet_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "#---------------------------------------------\n",
    "#Settings: definicao dos parametros da rede:\n",
    "n_classes = 10                     # A base de dados Cifar10 tem 10 classes de objetos!!!!\n",
    "nepochs = 30                       # Numero de epocas para o treinamento!!! \n",
    "batch_size = 128                   # Numero de imagens por batch!!!\n",
    "image_size = 32                    # Todas as imagens devem ser redimensionadas para 32x32 pixels!!!\n",
    "nchannels = 3                      # Numero de canais na imagem!!!\n",
    "learning_rate = 1e-4               # Taxa de aprendizado!!!\n",
    "keep_probability = 0.5             # Taxa de dropout!!!\n",
    "TRAIN_DIR = './cifar10-keras/treino/'\n",
    "TEST_DIR = './cifar10-keras/teste/'\n",
    "cnn_last_layer_length = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#---------------------------------------------\n",
    "def get_cnn_model ():\n",
    "\n",
    "    input_shape = (image_size, image_size, nchannels)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(cnn_last_layer_length, activation='relu', name='fc1'))\n",
    "    model.add(Dropout(keep_probability))\n",
    "    model.add(Dense(cnn_last_layer_length, activation='relu', name='fc2'))\n",
    "    model.add(Dropout(keep_probability))\n",
    "    \n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "#---------------------------------------------\n",
    "def get_vgg_model ():\n",
    "\n",
    "    input_shape = (image_size, image_size, nchannels)\n",
    "    input_tensor = Input (shape=input_shape)\n",
    "    baseModel = VGG16 (weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "\n",
    "    modelStruct = baseModel.output\n",
    "    modelStruct = Flatten(input_shape=baseModel.output_shape[1:])(modelStruct)\n",
    "    \n",
    "    modelStruct = Dense(cnn_last_layer_length, activation='relu', name='fc1')(modelStruct)\n",
    "    modelStruct = Dropout(keep_probability)(modelStruct)\n",
    "    modelStruct = Dense(cnn_last_layer_length, activation='relu', name='fc2')(modelStruct)\n",
    "    modelStruct = Dropout(keep_probability )(modelStruct)\n",
    "    predictions = Dense(n_classes, activation='softmax')(modelStruct)\n",
    "\n",
    "    model = Model(input=[baseModel.input], output=predictions)\n",
    "\n",
    "    for i,layer in enumerate(model.layers):\n",
    "        layer.trainable = True\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 129s 2us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cordeiro/env/py3im/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, image_size, image_size)\n",
    "else:\n",
    "    input_shape = (image_size, image_size, 3)\n",
    "\n",
    "#model = get_cnn_model ()\n",
    "model = get_vgg_model ()\n",
    "\n",
    "model.compile(optimizer=Adam(lr=learning_rate),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "                  rescale = 1./255, \n",
    "                  horizontal_flip = True, \n",
    "                  vertical_flip = True, \n",
    "                  width_shift_range=0.2,\n",
    "                  height_shift_range=0.2,\n",
    "                  zoom_range = [0.9, 1.0]\n",
    "               )\n",
    "\n",
    "test_datagen = ImageDataGenerator (\n",
    "                  rescale=1./255\n",
    "               )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory (\n",
    "    TEST_DIR,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "STEP_SIZE_TEST = test_generator.n // test_generator.batch_size\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1030 15:07:01.963375 140028607960896 deprecation_wrapper.py:119] From /home/cordeiro/env/py3im/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "102/312 [========>.....................] - ETA: 31:29 - loss: 2.2689 - accuracy: 0.1412"
     ]
    }
   ],
   "source": [
    "model.fit_generator (\n",
    "    train_generator,\n",
    "    steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "    epochs=nepochs,\n",
    "    validation_data = test_generator,\n",
    "    validation_steps = STEP_SIZE_TEST\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3im",
   "language": "python",
   "name": "py3im"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
